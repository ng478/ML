{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/ng478/uncategorized\" target=\"_blank\">https://app.wandb.ai/ng478/uncategorized</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/ng478/uncategorized/runs/3oten3tg\" target=\"_blank\">https://app.wandb.ai/ng478/uncategorized/runs/3oten3tg</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.22 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "from wandb import magic\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# predicts 7/12, 8/11 or 6/8\n",
    "sequences = ['H375S', 'WT', 'LM', 'LM_H375S', 'H375S_H61Y', 'H375S_Q105H', 'H375S_V108I', 'H375S_Q105H_V108I', 'H375S_NIK474_476DMR', 'H375S_Q105H_V108I_NIK474_476DMR', 'H375T', 'LM_H375T']\n",
    "#sequences = ['H375S', 'WT', 'LM', 'LM_H375S', 'H375S_H61Y', 'H375S_Q105H', 'H375S_V108I', 'H375S_Q105H_V108I', 'H375S_Q105H_V108I_NIK474_476DMR', 'H375T', 'LM_H375T']\n",
    "#sequences = ['H375S', 'H375S_H61Y', 'H375S_Q105H', 'H375S_V108I', 'H375S_Q105H_V108I', 'H375S_NIK474_476DMR', 'H375S_Q105H_V108I_NIK474_476DMR', 'H375T']\n",
    "#sequences = ['H375S']\n",
    "\n",
    "active = [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1]  \n",
    "#active = [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1] \n",
    "#active = [0, 0, 0, 0, 0, 1, 0, 1] \n",
    "#active = [0]\n",
    "\n",
    "\n",
    "my_dict = {}\n",
    "\n",
    "for seq,act in zip(sequences,active):\n",
    "\n",
    "    df=pd.read_csv('output-rgyr-%s.dat'%seq, sep=\" \",header=None)\n",
    "    df1=pd.read_csv('output-charge-%s.dat'%seq, sep=\" \",header=None)\n",
    "    df2=pd.read_csv('output-dot-%s.dat'%seq, sep=\" \",header=None)\n",
    "    df3=pd.read_csv('output-%s.dat'%seq, sep=\" \",header=None)\n",
    "    df4=pd.read_csv('output-pt0-mag-%s.dat'%seq, sep=\" \",header=None)\n",
    "    df5=pd.read_csv('output-charge-std-%s.dat'%seq, sep=\" \",header=None)\n",
    "    my_dict[seq]=[df4,act]\n",
    "    #input data is df4, which is the average dipole moment per time step across the 5 replicate trajectories\n",
    "    #y = np.array(my_dict['H375S'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "#Here I am adding each first column of the data as an array per sequence\n",
    "#For example, the average dipole moment across 5 replicas of the first timestep for H375S is: -3.67851 -2.19384 1.71885\n",
    "for seq in sequences:\n",
    "    a.append(my_dict[seq][0].values)\n",
    "#print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.63005  6.52154  5.75852  5.12014  5.44543]\n",
      " [ 6.27117  5.75019  7.8948   4.84391  3.24225]\n",
      " [ 6.63515  6.45865  4.68326  8.20309  5.68154]\n",
      " [10.8525   7.23245 10.6234   5.11686  4.84477]\n",
      " [ 6.90239  9.81281 10.731   12.7027   7.0801 ]\n",
      " [ 5.32339 10.7344   6.79031 10.5846   9.84809]\n",
      " [11.0906   6.16148  5.02688  5.85155  3.7702 ]\n",
      " [ 3.97945 12.8192   6.14302  7.61566  8.26343]\n",
      " [ 6.58074  8.26008  2.76228  4.15795  2.73069]\n",
      " [ 6.51494 16.4857   8.19625  1.80879  4.09538]\n",
      " [ 3.59118  6.39338  3.03531  3.24092  4.43871]\n",
      " [ 6.39996  6.06392  1.97374  3.88145  6.14879]]\n"
     ]
    }
   ],
   "source": [
    "#a = a.reshape(a.shape[0], -1)  \n",
    "a = np.asarray(a)\n",
    "a = a.reshape(a.shape[0], -1)\n",
    "print (a)\n",
    "X = a\n",
    "Y = active\n",
    "#print (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the reason the shape of a below is 12, 60000 is that there are 12 sequences and 20000 timesteps x 3 coordinates = 60000 features\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.22 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim=5, activation='relu'))\n",
    "model.add(Dense(4, activation='relu')) \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X, Y, epochs=300, batch_size=100, verbose=0)\n",
    "# make class predictions with the model\n",
    "predictions = model.predict_classes(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences2 = ['H375S_H61Y_Q105H_V108I', 'H375T_H61Y_Q105H_V108I', 'H61Y_Q105H_V108I']\n",
    "#sequences = ['H375S']\n",
    "my_dict2 = {}\n",
    "\n",
    "for seq2 in sequences2:\n",
    "\n",
    "    df=pd.read_csv('output-rgyr-%s.dat'%seq2, sep=\" \",header=None)\n",
    "    df1=pd.read_csv('output-charge-%s.dat'%seq2, sep=\" \",header=None)\n",
    "    df2=pd.read_csv('output-dot-%s.dat'%seq, sep=\" \",header=None)\n",
    "    df3=pd.read_csv('output-%s.dat'%seq, sep=\" \",header=None)\n",
    "    df4=pd.read_csv('output-pt0-mag-%s.dat'%seq, sep=\" \", header=None)\n",
    "    df5=pd.read_csv('output-charge-std-%s.dat'%seq, sep=\" \",header=None)\n",
    "    #df=0 \n",
    "    my_dict2[seq2]=[df4]\n",
    "   \n",
    "#df.columns= my_dict[\"H375S\"][0].columns\n",
    "#df1.columns=my_dict[\"H375S\"][0].columns\n",
    "#distance2 = my_dict2[\"H375S_H61Y_Q105H_V108I\"][0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = []\n",
    "for seq2 in sequences2:\n",
    "    c.append(my_dict2[seq2][0].values)\n",
    "    #c = c.tolist()\n",
    "#print(c)\n",
    "c = np.asarray(c)\n",
    "\n",
    "c = c.reshape(c.shape[0], -1)\n",
    "#c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.22 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(predicted 0)\n",
      "(predicted 1)\n",
      "(predicted 0)\n",
      "(predicted 1)\n",
      "(predicted 0)\n",
      "(predicted 0)\n",
      "(predicted 1)\n",
      "(predicted 0)\n",
      "(predicted 1)\n",
      "(predicted 1)\n",
      "(predicted 0)\n",
      "(predicted 1)\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/natasha/.local/lib/python3.7/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.422567). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n",
      "/home/natasha/.local/lib/python3.7/site-packages/keras/callbacks/callbacks.py:95: RuntimeWarning: Method (on_train_batch_end) is slow compared to the batch update (0.215000). Check your callbacks.\n",
      "  % (hook_name, delta_t_median), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "1\n",
      "no\n",
      "2\n",
      "no\n",
      "3\n",
      "no\n",
      "4\n",
      "no\n",
      "5\n",
      "no\n",
      "6\n",
      "no\n",
      "7\n",
      "yes\n",
      "8\n",
      "yes\n",
      "9\n",
      "yes\n",
      "10\n",
      "yes\n",
      "11\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "reference = np.array(active)\n",
    "t = model.predict_classes(X)\n",
    "for i in range(12):\n",
    "    print('(predicted %d)' % (t[i]))\n",
    "for x in range(12):\n",
    "    print (x)\n",
    "    z = np.delete(a, x, 0)\n",
    "    y = np.delete(active, x, 0)\n",
    "    model.fit(z, y, epochs=150, batch_size=10, verbose=0)\n",
    "    #print (y)\n",
    "    t = model.predict_classes(X)\n",
    "    #for i in range(12):\n",
    "        #print('%d (expected %d)' % (t[i], Y[i]))\n",
    "    #t=t.reshape(-1, 1).tolist()\n",
    "    zz=[tt[0] for tt in t]\n",
    "    #print (zz)\n",
    "    #print (Y)\n",
    "    e = zz == Y\n",
    "    #print (e)\n",
    "    if np.all(e):\n",
    "        print(\"yes\")\n",
    "    else:   \n",
    "        print (\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (expected 0)\n",
      "0 (expected 0)\n",
      "0 (expected 0)\n",
      "1 (expected 1)\n",
      "0 (expected 0)\n",
      "0 (expected 0)\n",
      "0 (expected 0)\n",
      "0 (expected 0)\n",
      "1 (expected 1)\n",
      "0 (expected 0)\n",
      "1 (expected 1)\n",
      "1 (expected 1)\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(a)\n",
    "for i in range(12):\n",
    "    print('%d (expected %d)' % (predictions[i], Y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(c)\n",
    "for i in range(3):\n",
    "    print('%d' % (predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
